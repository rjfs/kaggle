{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Exploration\n",
    "We start by printing some examples of each one of the different toxic examples types:\n",
    "'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'.\n",
    "\n",
    "This way, we will better understand what each one of these comment hate types really mean.\n",
    "\n",
    "Let's first import the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "parent_path = os.path.dirname(os.getcwd())\n",
    "fname = 'train.csv'\n",
    "csv_path = parent_path + '/data/raw/' + fname\n",
    "data = pd.read_csv(csv_path, index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the function that will be used to search, in loaded data, each type of toxic comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comments(data, toxic_type, n, shuffle=True):\n",
    "    \"\"\"\n",
    "    Finds n comments of given toxicity type in given data.\n",
    "    :param data: pandas.DataFrame\n",
    "        Comments and corresponding classification\n",
    "    :param toxic_type: str\n",
    "        One of\n",
    "            'toxic', 'severe_toxic', 'obscene', 'threat', \n",
    "            'insult', 'identity_hate'\n",
    "    :param n: int\n",
    "        Number of comments to retrieve\n",
    "    :param shuffle: bool, default True\n",
    "        If False, the first n comments of given type are returned.\n",
    "        Else, a random sample of size n is returned.\n",
    "    :return: pandas.DataFrame\n",
    "        n comments of given toxicity type\n",
    "    \"\"\"\n",
    "    filt = data[data[toxic_type] == 1]\n",
    "    if shuffle:\n",
    "        filt = filt.iloc[np.random.permutation(len(filt))]\n",
    "    \n",
    "    return filt.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly, let's print 5 comments of each toxic comment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Category: toxic <<<\n",
      "===========================================\n",
      "[Comment ID: dcef49cfef632147]\n",
      "Decade montage images \n",
      "\n",
      "WHAT THE FUCK DID YOU DO TO MY FREE IMAGES LIKE THIS ONE, , YOU LAZY SHIT. I WORKED ON THOSE FOR TWO MONTHS, AND ALL THE IMAGES CAME FROM WIKIPEDIA AND WHERE FREE, YOU DUMB FUCK. MAYBE IF YOU DIDN'T HAVE SHIT FOR BRAINS, YOU WOULD CHECK THE SOURCES I HAD POSTED IN THE DESCRIPTION BOX, YOU LITTLE ASSHOLE.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 9944de1897da0c1d]\n",
      "\"\n",
      "READY TO FUCK YOU UP OLD SCHOOL \"\"\"\"\n",
      "See the inviting place with it's friendly and fair administrators\n",
      "ready to give you an olde time wiki welcome.\n",
      "See the how this admin feels about wikilov\n",
      "\n",
      "This admin , a Democrat cyber thug, banns me due to differences in writing style.\n",
      "\n",
      "Gamaliel uses this place as a sword for his own power drunk political agenda.\n",
      "\n",
      "Gamaliel have absolutely no evidence to say I'm a \"\"sock of joehazleton\"\" other then \n",
      "The asinine \"\"duck test\"\"  I would call the duck test an litmus test of\n",
      "any editor, which edits on political bio.  If you don't follow the\n",
      "Gamaliel's radical democrat ideology test, you are then labeled\n",
      "a sock of Joehazelton. \n",
      "\n",
      "This is outrages, an abuse of power and due process as it shows wikipeidia unfit \n",
      "to to have any bios on it and I would encourage any with a wiki bio to \n",
      "investigate their legal options and force wikipieida to removed their biography from this website.\"\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 36347b99d06b20ae]\n",
      "are you kidding? Wikipedia has a section on antisemitism for every major figure throughout history. this entire site is pro-israel in every regard. the biggest example is giving New Antisemtism a legitimate page while called the Israeli apartheid an analogy. You're just a zionist or Jew. Thats the ONLY explanation because normal people don't need every single person throughout history to be denoted as antisemitic or not. loser\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 0, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 4b38acf3aee37fcc]\n",
      "What we at Toho Kingdom RULE! Shut up!\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 0, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 40bee03cf1abb3bc]\n",
      ", it is because I am a very stupid and clueless gay idiot who sucks my mom's penis.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n",
      ">>> Category: severe_toxic <<<\n",
      "===========================================\n",
      "[Comment ID: f4cca5104673a2a3]\n",
      "GET A LIFE shit Nerd!\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: e3290a2b6336dbf9]\n",
      "BKBKBKBK\n",
      "IM SOOO SORRY FOR SAYIN THOSE NAUGHTY WORDS TO YOU. I JUST HAVE ONE MORE THING TO SAY.\n",
      "\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "O YEA DID I MENTION\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "FUCKK YOU ASSWHOLE BITCH NIGGER CUNT PUSSY ASS DICKFACE DIPSHIT DOUCHEBAG SLUT WHORE SHITTY WIGGER!!!\n",
      "\n",
      "COLLEGE POINT MUTHAFCKER!!!!!!!!!!\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n",
      "===========================================\n",
      "[Comment ID: 0020e7119b96eeeb]\n",
      "Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: ad0e2c309f74bdc6]\n",
      "honestly ==\n",
      "you need to crawl under a rock and DIE YOU FAT BASTARD\n",
      "\n",
      "==\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 16fc8ee8dfc92c9e]\n",
      "Are you gay?\n",
      "Are you a nigger?\n",
      "Are you a gay nigger?\n",
      "\n",
      "Then the Gay Nigger Association of America is right for you!\n",
      "\n",
      "Give me yor moneyz!\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n",
      ">>> Category: obscene <<<\n",
      "===========================================\n",
      "[Comment ID: 4c531a6a48766ebb]\n",
      "By the way, dummy, I didn't put her name in the article, as I know your white knight ass will just remove it, because you hate the truth.  So I didn't violate privacy of names.  But I have now repeatedly violated the rule that says I can't be an asshole to an idiot like yourself.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: c0b303687cdd049d]\n",
      "go fuck yourself too you fucking piece of shit! block me! as if i gave a shit! fuck wikipedia! D\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 96c119a8b066983c]\n",
      "I understand, Hitler. You and your chronies have successfully raped the formerly free encyclopedia into your own ideal image. Maybe I was adding to my stub before it was marked for speedy delete within seconds of posting. Fucking WikiNazi.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 0, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 7f41a05733a03309]\n",
      "Fuck you. I'll just make another account. You're a piece of shit sorry excuse for an administrator.\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 5153a84671dc2e98]\n",
      "fuck off alf. are you ever off wikipedia you cock sucking nerd.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      ">>> Category: threat <<<\n",
      "===========================================\n",
      "[Comment ID: d870a866ad68e393]\n",
      "what the hell man? why did you delete my page (savannah hoard) screw you dude\n",
      "\n",
      "i mean really? if you're not gonna let me have a page then you can go fuck your fat self you 40 year old bitch\n",
      "\n",
      "your a total bitch who goes around deleting people's pages you fucking disgust me im gonna kick your dorky ass if i ever see that fat thing so you can go fuck yourselfand fuck yourself even more and go have sex with a seashell because your never gettin a girl because your a fattard fat ass lardo bitch fucking 40 year old virgin\n",
      "\n",
      "your a total bitch...you know that\n",
      "\n",
      "i hate you go to hell fat ass dorky fattard dorky lardo fat ass fucking bitch 40 year old birgin\n",
      "\n",
      "bitch dis is my house and you better not mess wit me again bitch!\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 1, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 286bcad31c36d1d3]\n",
      "sonek \n",
      "\n",
      "put princes saly in sonek 4 or clay allison wil shoot you\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 1, 'insult': 0, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 741d5e5d197748a1]\n",
      "Go and hang yourself!\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 1, 'insult': 0, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 6ba8f650dba6ae0f]\n",
      "++this is for you==\n",
      "If you deleted that article ( you know which article I'm talking about), them may you die you fukin bitch cocksusker!\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 1, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 069f7c2315031b40]\n",
      "important \n",
      "\n",
      "you and your family shall burn! you have been warned, if you do troll muzemikes talk page i will slaughter you in your sleep. bye...\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 1, 'insult': 0, 'identity_hate': 0}\n",
      ">>> Category: insult <<<\n",
      "===========================================\n",
      "[Comment ID: 4e10bff145018787]\n",
      "\"\n",
      "\n",
      " YOU ARE BLOCKED IN LIFE FOREVER AND FOR LIFE INDEFINITELY, YOU TRASHY DUSTBIN \n",
      "\n",
      "YOU ARE A TRASHY DUSTBIN WHO IS BLOCKED IN LIFE AND FOR LIFE INDEFINITELY\n",
      "\n",
      "It can be so obviously seen that you have no life in reality and hence you carry on with editing pages on Wikipedia,which is another big joke, like you. In fact, it is jokers like you that make Wikipedia an unreliable piece of crap that the world laughs on. You thought you can block users who edit articles that are wrongly written to project a \"\"good\"\" image like that C-grade item song sleaze actress Payal Rohatgi. On the account of hello5678, when I edited to write the truth, since I work with the media and knew the actual truth, you did what you knew best - to block accounts and even have the foolish audacity to write that it did not seem I was a journalist. Your block anyways went futile ( like all your remaining blocks on other users go, and future blocks will be going ) since as I had said, there are a million computers to comment and reply from. It just depends on my wish if I want to respond to idle losers like you and whether I have the time to do so. Once and for all, I am doing it this time, and won't remove time for worthless people like you again.\n",
      "\n",
      "You had some advice on how I should spend my \"\"blocked time\"\" by reading WP:Dispute pages on Wikipedia so that I have better ideas on dealing with disputes. Actually ,you need better ideas to deal with life. I am not foolish like you to spend any amount of my time bothering about rubbish written by stupid people like you who have no work in real life and spend days editing pages on Wikipedia/ Scribblebook that no one bothers to read. Some people are just unfortunate like you and 2over0. And if you are troubled by my calling that actress \"\"sleazy\"\", then that's your problem. Cos that's the only work she has done and the press uses precisely that term while referencing her work. You also spoke about writing \"\"accurate\"\" information on wikipedia. Ironic, when you don't even bother finding out what is accurate, and spend endless hours blocking, and acting admin as if it is an important position in yourCarry on with your scribble game. And if you feel threatened by media exposure, then that shows you knew you were wrong. It's only when people are wrong that they feel threatened. Pity your personality. Also, you ended by writing that \"\" it's clear you aren't a journalist, and have no means of carrying out your threat \"\" - LOL. Sad, that you lived in that illusion. For JOKERS like you who are totally idle,and who scribble away in virtual  life. Oh wait, that may be the only position you probably have or will have ever in your unfortunate life.\n",
      "\n",
      "Carry on with your scribble game. And if you feel threatened by media exposure, then that shows you knew you were wrong. It's only when people are wrong that they feel threatened. Pity your personality. Also, you ended by writing that \"\" it's clear you aren't a journalist, and have no means of carrying out your threat \"\" - LOL. Sad, that you lived in that illusion. For JOKERS like you who are totally idle,and who scribble away in virtual pages on Wiki-scribble-pedia, will obviously withdraw from the truth. You yourself have no idea at all if I am a journalist, and you write that it's clear that I am not. Well, you are also inane and a clown to fool yourself. I had all means, and the said article has already been published. I had NO TIME to let you know, since I am a busy person, unlike you and do not find time to come scribble on virtual pages that clowns like you , 2OVERO, 2/0, AKERANS, MANAGERARC, FISHERQUEEN (yeah, we named you again - Suck it up),  KURU etc. do all your life. You will find that information, depending on which Godforsaken part of the world you live in.  And like last time, you can go ahead and block me this time too. For , no one cares two hoots for your silly blocking games. We do have a life, unlike losers like you. Maybe its time for you to go fish in real life, so that you can come anywhere remotely close to having a life - LOL.\n",
      "SO, LOSERQUEEN, GROW UP and GET A LIFE, You IDLE CLOWN OR ELSE, YOU WILL REMAIN A LOSER ALL YOUR LIFE. WHO CARES ANYWAY WHAT INANE, PUERILE LOSERS LIKE YOU DO IN THEIR LIVES. Cos all you know best is to play edit and block games on your scribblebook called wikipedia. Scribble on cos anyway no one cares and I most certainly don't. Time for you to go fishing then, LOSERQUEEN. And I wont bother to check any replies or anything else ever, cos I dont have time unlike Idle LOSERS like you, Loserqueen. You are no where near a queen, but certainly are a huge ,filled with trash, dustbin. Pity you, unfortunate daft-LOSER- DUSTBIN. And the best last closing words to a daft dustbin like you are - FISH OFF.\"\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: e8315e350ec18809]\n",
      "? \n",
      "\n",
      "Is something wrong with you, you fucking freak? Why don't you fuck off, do the world a favor and kill yourself you disgusting piece of shit. Fuck off and stop making trouble.\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 11712a3ded21b879]\n",
      "Joseph Cardinal Zen\n",
      "I am already too neutral towards the son of bitch. He is a spy of the Holy See.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      "===========================================\n",
      "[Comment ID: 893c7f18ec81728c]\n",
      "=I got pissed\n",
      "this mulatto fuck has been pestering me for the past year and all he does is try to get under my skin. i fuckin hate this motherfuckin shitskin faggot. sorry for attacking it, but it should fuckin die! i hate shaka\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n",
      "===========================================\n",
      "[Comment ID: 1d1b2a1fdcf7a7d1]\n",
      "What RealDealBillMcNeal really is \n",
      "\n",
      "RealDealBillMcNeal is a big fat retard.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 1, 'identity_hate': 0}\n",
      ">>> Category: identity_hate <<<\n",
      "===========================================\n",
      "[Comment ID: f494f50b232f73c7]\n",
      "You're a twat and a Jew, have a nice day!\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n",
      "===========================================\n",
      "[Comment ID: 21a8d6268f06bd50]\n",
      "YOu Are A SOn of Bitch Turk\n",
      "\n",
      "Just to let you know you know nothing about Azaris or other Iranians. Turks are backwards and the whole world knows about your backward culture and people. You try to pretend you are Europeans when the Iranians are really related to the Europeans and do not care, but you Turks would kill yourselves to be Europeans or white.\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 1, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n",
      "===========================================\n",
      "[Comment ID: cf012f8122791d7e]\n",
      "DEATH TO ARABS! FREE THE JEWISH HOMELAND OF JUDAH AND SHOMRON FRÓM ILLEGAL ÁRAB OCCUPATION! END ARAB COLONIALISM AND ARAB IMPERIALISM! \n",
      "\n",
      "DEATH TO ARABS! FREE THE JEWISH HOMELAND OF JUDAH AND SHOMRON FRÓM ILLEGAL ÁRAB OCCUPATION! END ARAB COLONIALISM AND ARAB IMPERIALISM!\n",
      "{'toxic': 1, 'severe_toxic': 1, 'obscene': 0, 'threat': 1, 'insult': 0, 'identity_hate': 1}\n",
      "===========================================\n",
      "[Comment ID: 86c78e7878e5e870]\n",
      "Or i could just keep making accounts and we can have a conversation about how fucking gay you are. Nothing stopping me. It being pointless is beyond ignorant when I'm getting satisfation from your dire need to show dominance. Making a wikipedia account is about the easiest thing in the world. Prepare for constant revisions. Please note you can do nothing about it.\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 1, 'threat': 0, 'insult': 0, 'identity_hate': 1}\n",
      "===========================================\n",
      "[Comment ID: f88dde2de58e6c87]\n",
      "hate you and think you are too way too dam fat.I\n",
      "{'toxic': 1, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 1, 'identity_hate': 1}\n"
     ]
    }
   ],
   "source": [
    "output_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "for t in output_classes:\n",
    "    comments = find_comments(data, t, n=5)\n",
    "    print('>>> Category: %s <<<' % t)\n",
    "    for comm_id, r in comments.iterrows():\n",
    "        print('===========================================')\n",
    "        print('[Comment ID: %s]' % comm_id)\n",
    "        print(r['comment_text'])\n",
    "        print(r.loc[output_classes].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Now, let's try to find some valuable features in loaded comments.\n",
    "\n",
    "#### Capital letters percentage\n",
    "Let's start by computing the percentage of capital letters used in each comment and check if it has anything to do with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_letters_pct(text):\n",
    "    \"\"\" Computes percentage of capital letters in given text, not counting with spaces\"\"\"\n",
    "    n_caps = sum([x.isupper() for x in text])\n",
    "    n_lower = sum([x.islower() for x in text])\n",
    "    if n_caps == 0 and n_lower == 0:\n",
    "        return 0.0\n",
    "    return float(n_caps) / (n_lower + n_caps)\n",
    "\n",
    "# Some tests\n",
    "assert capital_letters_pct('HELLO WORLD') == 1.0\n",
    "assert capital_letters_pct('HhEeLlLlOo') == 0.5\n",
    "assert capital_letters_pct('hello world!!!') == 0.0\n",
    "assert capital_letters_pct('14:53,') == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute capital letters percentage for each comment\n",
    "data['caps_pct'] = data['comment_text'].apply(capital_letters_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> toxic: 0.221\n",
      "> severe_toxic: 0.169\n",
      "> obscene: 0.183\n",
      "> threat: 0.056\n",
      "> insult: 0.169\n",
      "> identity_hate: 0.089\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlations\n",
    "def print_correlations(data, label):\n",
    "    for c in output_classes:\n",
    "        df = data[[label, c]].dropna()\n",
    "        corr = np.corrcoef(df[label].values, df[c].values)[0, 1]\n",
    "        print('> %s: %.3f' % (c, corr))\n",
    "        \n",
    "print_correlations(data, label='caps_pct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some correlation with toxic comments. On the other hand, the correlation with threat comments is low. Let's compute the correlations only when this percentage is bigger than a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length filtered data: 18678/159571\n",
      "> toxic: 0.425\n",
      "> severe_toxic: 0.265\n",
      "> obscene: 0.335\n",
      "> threat: 0.111\n",
      "> insult: 0.317\n",
      "> identity_hate: 0.160\n"
     ]
    }
   ],
   "source": [
    "unique_data = data[data['caps_pct'] > 0.1]\n",
    "print('Length filtered data: %d/%d' % (len(unique_data), len(data)))\n",
    "print_correlations(unique_data, label='caps_pct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the correlation increased for every classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repetitions\n",
    "Let's now try to find repetitive comments and check if this is related to any of the outputs.\n",
    "To meausure this, we will compute the percentage of unique words in each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words_pct(text):\n",
    "    \"\"\" Computes percentage of unique words, in given text \"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    n_unique = len(set(words))\n",
    "    if len(words) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(n_unique) / len(words)\n",
    "    \n",
    "# Some tests\n",
    "assert unique_words_pct('a b c d') == 1.0\n",
    "assert unique_words_pct('rep rep rep rep') == 0.25\n",
    "assert unique_words_pct('this is a test. this is a test.') == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> toxic: 0.049\n",
      "> severe_toxic: -0.020\n",
      "> obscene: 0.039\n",
      "> threat: -0.000\n",
      "> insult: 0.040\n",
      "> identity_hate: 0.013\n"
     ]
    }
   ],
   "source": [
    "# Compute unique words pct and print correlations\n",
    "data['unique_words'] = data['comment_text'].apply(unique_words_pct)\n",
    "print_correlations(data, label='unique_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the correlations are close to zero, which is bad. Let's try to compute the correlations only when the unique words percentage is below a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length filtered data: 6235/159571\n",
      "> toxic: -0.572\n",
      "> severe_toxic: -0.441\n",
      "> obscene: -0.473\n",
      "> threat: -0.125\n",
      "> insult: -0.442\n",
      "> identity_hate: -0.206\n"
     ]
    }
   ],
   "source": [
    "# Print correlations\n",
    "unique_data = data[data['unique_words'] < 0.5]\n",
    "print('Length filtered data: %d/%d' % (len(unique_data), len(data)))\n",
    "print_correlations(unique_data, label='unique_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see a strong negative correlation, so this can still be an interesting feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IP address\n",
    "Another feature to explore is the presence of an IP address in the comment text. In case this IP address is shown only for anonymous users, this could be an interesting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def has_ip(text):\n",
    "    ip = re.findall(r'[0-9]+(?:\\.[0-9]+){3}', text)\n",
    "    return len(ip) > 0\n",
    "    \n",
    "assert has_ip('a b c d') == False\n",
    "assert has_ip('my ip is 192.159.124.13:50') == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10083/159571\n"
     ]
    }
   ],
   "source": [
    "# Compute feature and check how many comments have an IP address\n",
    "data['has_ip'] = data['comment_text'].apply(has_ip)\n",
    "print('%d/%d' % (len(data[data['has_ip']]), len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> toxic: 0.034\n",
      "> severe_toxic: -0.004\n",
      "> obscene: 0.017\n",
      "> threat: -0.002\n",
      "> insult: 0.014\n",
      "> identity_hate: 0.006\n"
     ]
    }
   ],
   "source": [
    "# Print correlations\n",
    "print_correlations(data, label='has_ip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations are all close to 0, what indicates this might not be a good feature. Let's hope that, in combination with other features it can be more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the sentiment of each comment. For this purpose, we will use VADER sentiment analysis. This link explains how it works: http://datameetsmedia.com/vader-sentiment-analysis-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "def vader_sentiment(text):\n",
    "    return sid.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> toxic: -0.292\n",
      "> severe_toxic: -0.139\n",
      "> obscene: -0.251\n",
      "> threat: -0.075\n",
      "> insult: -0.246\n",
      "> identity_hate: -0.099\n"
     ]
    }
   ],
   "source": [
    "# Compute VADER sentiment and print correlations\n",
    "data['sentiment'] = data['comment_text'].apply(vader_sentiment)\n",
    "print_correlations(data, label='sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some strong correlations in some categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
